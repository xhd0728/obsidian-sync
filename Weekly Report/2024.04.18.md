- 本周工作：
	- 使用`LLM`对`chunk`进行分类，分类标准是判断`chunk`内容和`query`是否相关
	- 为获得较好的效果，只使用LLM对相关性做二分类任务
	- 将返回`相关`的`chunk`拼接，将拼接后的`doc`和`query`送入`LLM`，计算准确率
	- chunk使用以下三种设置：
		- 4000
		- 6000
		- 8000
	- 过低或过高将产生成本问题和LLM输入限制问题
	- ![image.png](https://cdn.jsdelivr.net/gh/xhd0728/oss-github-picgo-repository@main/picgo/202404131318246.png)
- QY的工作
	- 和@lixinze师兄讨论sft数据生成
	- 目前在统计爬取的数据中`related works`部分中出现的`citation`，看一下数量分布
	- `semantic scholar`的数据库有问题，有些论文的引用标注有错误，导致树状结构异常
	- 下周解决一下噪声问题
- 实验结果：
	- [Google Doc](https://docs.google.com/spreadsheets/d/1UdHcoh4dU7Oa7syR5WN13vz4IhYmerFhZdTEZ-kAEvY/edit?usp=sharing)
	- `summary`处理后有较好的表现，在文本压缩率达到`73%`以上时，准确率损失低于`2%`
	- 目前`gpt-3.5-turbo`和`gemini-pro`仍不能有效的提取文本摘要信息
- 下周工作：
	- 尝试以`Abstract`为基础，将文章剩余部分的`chunk`逐个与`query`进行比对，使用`ppl`计算相关程度，将高于阈值的`chunk`添加到`doc_list`中