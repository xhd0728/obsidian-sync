- 本周工作
	- 调研数据集
		- CSQA: CommonsenseQA 2.0 数据集包含14343个关于日常常识知识的是/否问题（或断言）。该数据集是通过游戏化收集的，游戏玩家的目标是使用特定短语提出误导竞争对手人工智能的问题。这种游戏环境提高了用户参与度，同时让游戏设计者能够控制所收集的数据，使我们能够大规模收集高质量的数据。
		- StrategyQA: StrategyQA 是一个专注于开放领域问题的问答基准，其中所需的推理步骤隐含在问题中，并且应该使用策略来推断。StrategyQA 包括2780个示例，每个示例都包含一个策略问题、其分解和证据段落。
		- QUEST: 包含3357个具有💡**隐式集合操作**的自然语言查询的数据集，映射到与维基百科文档相对应的一组实体。该数据集挑战模型将查询中提到的多个约束与文档中的相应证据相匹配，并正确执行各种集合操作。该数据集是使用维基百科类别名称半自动构建的。查询由各个类别自动组成，然后由众包人员进行解释并进一步验证其自然性和流畅性。
		- ToolQA: 是一个开源数据集，专门用于评估💡**工具增强**的大型语言模型 (LLM)。该存储库提供了数据集、相应的数据生成代码以及数据集上基线的实现。
		- ![](https://cdn.jsdelivr.net/gh/xhd0728/oss-github-picgo-repository/picgo/20231214155223.png)
		- ![](https://aisholar.s3.ap-northeast-1.amazonaws.com/posts/July2023/TooQA_fig2.png)
	- 读论文 **Chain-of-Verification Reduces Hallucination in Large Language Models**（验证链）
		- 🚩生成基线响应：给定一个查询，使用LLM生成响应。
		- 🚩计划验证：给定查询和基线响应，生成一个验证问题列表，帮助自我分析原始响应中是否有任何错误。
		- 🚩执行验证：依次回答每个验证问题，然后对照原始回答检查答案，以检查不一致或错误。
			- **joint**: 计划和执行（步骤2和3）通过使用单个LLM提示符来完成，由此少数镜头演示包括验证问题及其紧接在问题之后的答案。在这种方法中，不需要单独的提示。
			- **2-step**: 将计划和执行分成不同的步骤，两者都有自己的LLM提示符。在第一步中，计划提示基线响应条件。从计划中产生的验证问题在第二步中得到回答，关键是给LLM提示的上下文只包含问题，而不包含原始基线响应，因此不能直接重复这些答案。
			- **factored**: 将所有问题作为单独的提示独立回答。虽然这可能在计算上更昂贵，需要执行更多的LLM提示，但它们可以并行运行，因此可以批处理。
			- **factor+revise**: 通过一个额外的LLM提示符将此作为一个有意的步骤来执行，这可能会使最终系统更容易明确地对此步骤进行推理。
		- 🚩生成最终验证响应：给定发现的不一致之处（如果有），生成包含验证结果的修订响应。
		- ![image.png|500](https://cdn.jsdelivr.net/gh/xhd0728/oss-github-picgo-repository/picgo/20231212143512.png)
	- 综述: **Survey of Hallucination in Natural Language Generation**
		- 幻觉的成因
			- 数据幻觉：数据集中源和目标之间的不匹配
			- 训练和推理产生的幻觉：
				- ⭐**不完全表征学习**
				- 错误解码
				- 偏差爆炸
				- 参数知识偏差
		- 幻觉测量指标
			- 统计度量：
				- PARENT：n-gram词汇蕴含将生成的文本与源表和目标文本进行匹配
				- PARENT-T：仅使用表的内容作为参考来简化PARENT
				- unigram F1→knowledge F1：用户基于知识的对话系统（KGD）
				- BVSS：句子相似性度量，测量NMT中的句子充分性
			- 基于模型的度量：
				- 基于信息提取
				- 基于问答
				- 自然语言推理度量
				- ⭐**忠实度分类度量**
					- > 为了改进基于自然语言推理（NLI）的度量标准，构建了特定任务的数据集以从NLI度量中改进。Liu等人[84]和Zhou等人[168]通过在训练实例中自动插入幻觉来构建了句法数据。Santhanam等人[116]和Honovich等人[54]为对话回复的忠实度分类构建了新的语料库。他们通过判断每个回复是否虚构，手动注释了Wizard-of-Wikipedia数据集[24]，一个知识图谱驱动对话（KGD）数据集。由于NLI数据集的蕴涵或中性标签与忠实度不等价，因此忠实度特定的数据集可能优于NLI数据集。例如，假设“普京是美国总统”可以被视为对前提“普京是总统”中性或蕴涵。然而，从忠实度的角度来看，假设包含了不支持的信息“美国”，被认为是幻觉。
					- > 这个是处理训练数据的，对于api这种是不是可以做CoT的忠实度分类
				- 基于LM的度量
		- 幻觉缓解方法
			- 数据相关方法：
				- 建立一个可靠的数据集（这个目前应该是必须做的）
					- 短语修剪：删除范例句中不受源支持的短语
					- 去语境化：删除依赖于语境的词语
					- 句法修改：使净化后的句子流畅
				- 自动清理数据
				- 信息扩充
			- 建模和推理方法
	- 关于多模态的一点想法
		- Universal Vision-Language Dense Retrieval
		- 🔗**飞书**
