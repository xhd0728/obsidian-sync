论文阅读：Fine-tuning Language Models for Factuality（针对事实性对语言模型进行微调）
- 研究动机：
	- 仍然是为了解决幻觉问题
	- 对模型的响应进行手动检查事实性是一个耗时的过程，同时产生很高人力成本
- 创新点：
	- 最近的工作（2023.11）之前使用测量与外部知识库的一致性或大模型的置信度来判断开放性文本的真实性，直接偏好优化算法能够使用对可能的模型响应的偏好排序，在监督模仿之外的目标直接微调语言模型
	- 本文提出与RLHF或以事实为目标的解码策略相比，从现有的检索系统或本文提出的无检索方法自动生成的事实偏好排名中学习，可以显著提高llama2在未决主题上的真实性
	- 在生成传记或回答医学问题时，事实错误率分别降低了58%和40%