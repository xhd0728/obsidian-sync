- 论文学习
	- ActiveRAG，进行知识建构，将外部知识和模型内部知识进行融合
	- Chain of Note，为检索到的文档生成顺序阅读笔记，评估它们与输入问题的相关性
	- The Power of Noise，包含不相关的文档可以意外地将性能提高30%以上
	- Understanding the Effect of Noise in LLM Training Data with Algorithmic Chains of Thought，探究噪声的类型或强度如何影响下游性能的定量
- 目前期望解决的问题：
	- 噪声问题，能力较弱的LLM生成的回答以及低质量的语料库包含大量噪声
- 实验：
	- 基于MMLU数据集
	- 1. knowledge生成
		- 使用Llama2-13b对问题生成knowledge
		- 问题：生成的文本质量太差
	- 2. summary知识总结
		- 使用Baichuan2-13b对上一步生成的passage提取知识
	- 3. 将summary加入cot中，形成知识建构和连接
		- 使用能力较强的LLM，如ChatGPT，GPT4等对提取的知识做总结